{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada4fff",
   "metadata": {},
   "source": [
    "# Keras Implementation of UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926a989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\suruj\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010b89c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     -------------------------------------- 455.9/455.9 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.9/895.9 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "     -------------------------------------- 438.7/438.7 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     ---------------------------------------- 14.2/14.2 MB 5.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.5/65.5 kB 891.1 kB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "     ---------------------------------------- 124.6/124.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, oauthlib, keras-preprocessing, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.10.26 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 2.10.1 requires protobuf<5.0.0dev,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570a54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b32762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patchify\n",
      "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\suruj\\anaconda3\\lib\\site-packages (from patchify) (1.21.5)\n",
      "Installing collected packages: patchify\n",
      "Successfully installed patchify-0.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4acef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import patchify\n",
    "import tifffile as tiff\n",
    "import sklearn \n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375fb91",
   "metadata": {},
   "source": [
    "# Put The Images , it will great if the Image are in the tiff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c5697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_image_stack = tiff.imread(r\"-----/image.tiff\")\n",
    "# large_mask_stack = tiff.imread(r\"------/mask.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c272fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_patches = []\n",
    "for img in range(large_img_stack.shape[0]):\n",
    "    \n",
    "    large_image = large_image_stack[img]\n",
    "    \n",
    "    patches_img = patchify(large_image, (256,256), step=256)\n",
    "    \n",
    "    for in range(patches_img.shape[0]);\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            \n",
    "            single_patch_img = patches_img[i,j,:,:]\n",
    "            single_patch_img = (single_patch_img.astype)('float32')) / 255\n",
    "            \n",
    "            ##Scaling the images\n",
    "            \n",
    "            all_img_patches.append(single_path_img)\n",
    "            \n",
    "images = np.array(all_img_patches)\n",
    "images = np.expand_dies(images, -1)\n",
    "\n",
    "all_mask_patches = []\n",
    "for img in range(large_mask_stack.shape[0]):\n",
    "    \n",
    "    large_mask = large_mask_stack_[img]\n",
    "    \n",
    "    patches_mask = patchify(large_mask, (256,256), step=256)\n",
    "    \n",
    "    for in range(patches_mask.shape[0]):\n",
    "        for j in range(patches_mask.shape[1]):\n",
    "            \n",
    "            single_patch_mask = patches_mask[i,j,:,:]\n",
    "            single_patch_mask = single_patch_mask / 255.\n",
    "            \n",
    "            all_mask_patches.append(single_patch_mask)\n",
    "            \n",
    "masks = np.array(all_mask_matches)\n",
    "masks = np.expand_dims(masks,-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, Xtest , y_train, y_test = train_test_split(images, masks , test_size = 0.25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ac45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(X_train))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(X_train[image_number], (256,256)), cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(y_train[image_number] , (256,256)), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adf9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img_HEIGHT = images.shape[1]\n",
    "IMG_WIDTH =  images.shape[2]\n",
    "IMG_CHANNELS = images.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f39529",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH , IMG_CHANNELS)\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimize=Adam(lr = 1e-3), loss='binary_crossentropy' ,matrices=[])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86061604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement ImageDatagenerator (from versions: none)\n",
      "ERROR: No matching distribution found for ImageDatagenerator\n"
     ]
    }
   ],
   "source": [
    "pip install ImageDatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49cd4e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=24\n",
    "\n",
    "\n",
    "img_data_gen_args = dict(rotation_range=90,\n",
    "                        width_shift_range=0.3,\n",
    "                        height_shift_range=0.3,\n",
    "                        shear_range=0.5,\n",
    "                        zoom,range=0.3,\n",
    "                        horizontal_flip=True,\n",
    "                        vertical_flip=True,\n",
    "                        fill_mode=('reflect')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24b5643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_data_gen_args = dict(rotation_range=90,\n",
    "#                          width,shift_range=0.3,\n",
    "#                          height_shift_range=0.3,\n",
    "#                          shear_ranges=0.3,\n",
    "#                          zoom,ranges=0.3,\n",
    "#                          horizontal_flip=True,\n",
    "#                          vertical_flip=True,\n",
    "#                          vertical_flip=True,\n",
    "#                          fill_mode='reflect',\n",
    "#                          preproccesing_function = lamda x: np.where(x>0, 1, 0).astype()\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a8d34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "# #image_data_generator.fit(X_train, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fcd92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size= 0\n",
    "\n",
    "# image_generator = image_data_generator.flow(X_train, seed=seed, batch_size=batch_size)\n",
    "# valid_img_generator = image_data_generator.flow(X_test, seed=seed, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16b75954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "\n",
    "# mask_generator = mask_data_generate.flow(y_train,seed=seed, batch_size=batch.size)\n",
    "\n",
    "# valid_mask_generator = mask_data_generator.flow(y_test, seed=seed, batch_size=batch_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3702cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_image_mask_generator(image_generator, mask_generator):\n",
    "#     train_generator = zip(image_generator , mask_generator)\n",
    "#     for (img, mask) in train_generator:\n",
    "#         yield (img , mask)\n",
    "        \n",
    "        \n",
    "# my_generator = my_image_mask_generator(image_generator, mask_generator)\n",
    "# validation_datagen = myimage_mask_generator(valid_img_generator , valid_mask_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334a49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = image_generator.next()\n",
    "# y = mask_generator.next()\n",
    "# for i in range(0,1):\n",
    "#     image = x[i]\n",
    "#     mask = y[i]\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(image[:,:,0], cmap='gray')\n",
    "#     plt.imshowsubplot(1,2,3)\n",
    "#     plt.imshow(mask[:,:,0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c10e01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_per_epoch = 3*(len(X_train))//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a8e089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(my_generator, validation data=validation_datagen, steps_per_epoch=steps,\n",
    "#                              validation_steps=steps_per_epoch, epochs=25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac9962",
   "metadata": {},
   "source": [
    "# Plot the trainning and validation accuracy and loss at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9d1d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "# plt.plot(epochs, loss, 'y' , labels='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('loss')\n",
    "# plt.legend()\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b1adebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "\n",
    "# val_acc = history.history['val_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa71218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(#pochs , acc , 'y' , label='Traning acc')\n",
    "    \n",
    "# plt.plot(#pachs , val_acc, 'r' , label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
